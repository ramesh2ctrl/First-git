# Synopsis

Role provides a wrapper for data upload via Ansible Tower to SFS server destination path, which is defined in input variable `upload_url`.

Role is composed of 2 stages "prepare" and "upload", which are selectable by input variable `sfs_upload_stage`.

First stage "prepare" performs the following steps:
* creates a temporary folder on the Ansible Tower host under starting path defined by input variable `output_dir`;
* stores the full temp folder path into a host fact `hostvars.localhost.base_dir` on localhost.
This localhost host fact is available to all following plays in same playbook.
It can be used by tasks which require to export files from endpoints to SFS server.
Such tasks can upload their files to a temporary folder on the Tower defined in `hostvars.localhost.base_dir` and then just call this role again with `sfs_upload_stage` set to "upload" to perform the upload to SFS.

Second stage "upload" can perform the following steps:
* pickup the temporary data folder location on Tower host from the `hostvars.localhost.base_dir` fact, which was created by calling this role with `sfs_upload_stage: "prepare"`;
* (optional) merge all data files contents in the temporary data folder on the Tower into single summary file, leaving original files intact;
* compress all files in the temp folder on the Tower host into single ZIP archive;
* upload ZIP archive from Tower to SFS server;
* cleanup the temporary data folder on Tower host.

Various input variables are available to customize role behavior without code modification.

# Variables

### Mandatory
Parameter | Type (Choices) | Default | Comments
----------|----------------|---------|---------
__sfs_upload_stage__ | String (prepare\|upload) | prepare | (used in stage 1&2) Defines the stage of the wrapper to be executed. "prepare" = prepare variables and temporary folder for data on Tower; "upload" = upload data to SFS, then remove folder and data on Tower.
__output_dir__ | String | /tmp/gts-ansible/generic | (used in stage 1) Root folder full path for all temporary data of particular type on Tower
__upload_url__ | String | https://secure-file-service.cloudapps.pt.ibm.com/files | (used in stage 2) Root URL of the folder on SFS server to upload data to

### Optional
Parameter | Type (Choices) | Default | Comments
----------|----------------|---------|---------
__api_auth_by__ | String (password\|token) | password | (used in stage 1&2) Defines single authentication method to use when accessing both Tower and SFS APIs via HTTPS
__unpack_on_sfs__ | Boolean |  | (used in stage 2) Defines if uploaded compressed data should be unpacked by SFS upon upload and stored in SFS vault in original uncompressed state. By default this parameter is undefined and upload will use SFS server generic configuration.
__upload_results__ | Boolean | true | (used in stage 2) Enable upload of data files from temp folder on Tower to the SFS server
__merge_results__ | Boolean | false | (used in stage 2) Enable merging raw contents from all data files in temporary folder on Tower into single summary file
__upload_url_subfolder__ | String |  | (used in stage 2) Sub-folder path under "{{upload_url}}/{{org}}/{{project}}/" folder on SFS server to upload data to. Available since version 1.1.0
__output_file_name__ | String | "{{timestamp}}.zip" | (used in stage 2) Name of the packed data file to be uploaded to SFS. Available since version 1.1.0
__merge_filenames_regex__ | String | "\\\\.(txt\|csv)$" | (used in stage 2) Regex to select data files names for merging of contents. Used to avoid merging other accompanying uploaded files like archives or logs. Available since version 1.1.0
__merged_file_name__ | String | "merged_file_{{ timestamp }}.txt" | (used in stage 2) Name of the merged summary data file. Available since version 1.1.0
__merged_file_separator_text__ | String |  | (used in stage 2) Custom text string to separate contents of data files which are merged into summary file. Available since version 1.1.0
__force_temp_folder_cleanup__ | Boolean | true | (used in stage 2) Always cleanup temporary data folder on Tower host. Set to "false" to have temporary data folder on Tower be cleaned only if upload to SFS was executed and successful. Available since version 1.1.0

Role requires credential of type `Ansible Tower` to be provided to its Job Template. It is because this role uses shell environment variables `TOWER_HOST`, `TOWER_USERNAME` and `TOWER_PASSWORD` on localhost, which are generated by `Ansible Tower` credential type. Tower user in this credential must have at least "Member" and "Auditor" roles for the Tower Organization on which the role will run.

To authenticate to Tower and SFS REST APIs, this role will use:
* if `"api_auth_by: password"` - variables `TOWER_USERNAME` and `TOWER_PASSWORD` values as user:password with "Basic" authentication method;
* if `"api_auth_by: token"` - only variable `TOWER_PASSWORD` value as a token with "Bearer" token-based authentication method.


# Results from execution

This role makes some of its results available for other plays in playbook by registering them as facts on "localhost" in run-time.

Main returned value:
- hostvars.localhost.base_dir - Temporary folder full path prepared on Tower host for data to be uploaded to SFS. Folder path is composed as following: `{{ output_dir }}/{{ org }}/{{ project }}/{{ timestamp }}`. New path is generated and new folder is created each time this role is called with `sfs_upload_stage: "prepare"`.

Other returned values:
- hostvars.localhost.output_dir - from corresponding input variable
- hostvars.localhost.org        - Organization Name for current Job on Tower
- hostvars.localhost.project    - Project Name for current Job on Tower
- hostvars.localhost.timestamp  - Start time of this role execution with `sfs_upload_stage: "prepare"` on Tower

# Procedure

Role should be run ONLY in a play on single host "localhost" (Ansible Tower host).
This role needs to be run from Ansible Tower as it retrieves in run-time some inventory/job template data from the Ansible Tower instance it is running on.

# Support

 * This is a CACM managed solution, please raise any requests or issues at: [COMMON REPOSITORY](https://github.Ramesh Technologies.net/Continuous-Engineering/CACM_Common_Repository/issues)
 * For General Queries/Playbook help implementation you could try the bluemix portal: [#continuous-engineering](https://continuous-engineering.eu-de.mybluemix.net/cacm)
 * Author Information: Ravi Kumar Puneti, and Ponit Kaur

# Deployment

The role will be called internally within the main playbook. 
Below parameter needs to be passed under extra variables on Ansible Tower Template.

```
* upload_results: 'true'
* upload_url: 'https://ibmtansible7a1.test.de.sni.ibm.com:9443/files'
```

*Note*: Above mentioned `upload_url` is just an example. SME has to provide the account specific SFS url

# Known problems and limitations

* None

# Prerequisites

* Standard Ansible prerequisites (Python on target machine)

# Examples

```
- name: Prepare environment for upload to SFS in patch scan playbook
  hosts: localhost
  connection: local
  gather_facts: false
  tasks:
    - include_role:
        name: sfs_upload
      vars:
        sfs_upload_stage: "prepare"
        output_dir: "/tmp/gts-ansible/patchscan"
```

```
- name: Upload data to SFS
  hosts: localhost
  connection: local
  gather_facts: false
  tasks:
    - include_role:
        name: sfs_upload
      vars:
        sfs_upload_stage: "upload"
        output_file_name: "{{ custom_var }}_custom_text_{{ timestamp }}.zip"
```

# License

[Ramesh Technologies Intellectual Property](https://github.Ramesh Technologies.net/Continuous-Engineering/CE-Documentation/blob/master/files/LICENSE.md)
